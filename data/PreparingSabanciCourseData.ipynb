{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_courses_info(soup, major_name=None):\n",
    "    rows = soup.find(\"table\", {\"class\": \"datadisplaytable\"}).find(\"tbody\").find_all(\"tr\", recursive=False)\n",
    "    title_rows = rows[::2]\n",
    "    course_detail_rows = rows[1::2]\n",
    "\n",
    "    course_titles = [row.find(\"th\", {\"class\": \"ddlabel\"}).find(\"a\").text for row in title_rows]\n",
    "    course_descriptions = [row.find(\"td\", {\"class\": \"dddefault\"}).text.split(\"View Catalog Entry\")[0] for row in course_detail_rows]\n",
    "\n",
    "    all_class_info = []\n",
    "    for course_info_data in course_detail_rows:\n",
    "        class_info_data = course_info_data.find(\"table\", {\"class\": \"datadisplaytable\"}).find(\"tbody\")\n",
    "\n",
    "        headers = [x.text for x in class_info_data.find_all(\"th\")]\n",
    "        class_info_dict = {header: [] for header in headers}\n",
    "        for row in class_info_data.find_all(\"tr\")[1:]:\n",
    "            for i, cell in enumerate(row.find_all(\"td\")):\n",
    "                key = headers[i]\n",
    "                class_info_dict[key].append(cell.text)\n",
    "\n",
    "        class_info_df = pd.DataFrame(class_info_dict)\n",
    "\n",
    "        all_class_info.append(class_info_df)\n",
    "\n",
    "    course_docs = []\n",
    "    for course_title, course_description, class_info_df in zip(course_titles, course_descriptions, all_class_info):\n",
    "\n",
    "        if \"Master Thesis\" in course_title or \"Dissertation\" in course_title:\n",
    "            continue\n",
    "\n",
    "        if major_name is not None:\n",
    "            doc = major_name + \" courses\" + \"\\n\"\n",
    "        else:\n",
    "            doc = \"\"\n",
    "        doc += course_title + \"\\n\" + course_description + \"\\n\" + class_info_df.to_markdown()\n",
    "        \n",
    "        # Remove multiple new lines\n",
    "        doc = re.sub(r'\\n+', '\\n', doc)\n",
    "        course_docs.append(doc)\n",
    "    \n",
    "    return course_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_course_docs = []\n",
    "code2name = {\n",
    "    \"DA\": \"Data Analytics\",\n",
    "    \"CS\": \"Computer Science\",\n",
    "    \"ECON\": \"Economics\",\n",
    "    \"IE\": \"Industrial Engineering\",\n",
    "}\n",
    "\n",
    "for file_name in os.listdir(\"data/sabanci_course_pages/\"):\n",
    "    file_path = os.path.join(\"data/sabanci_course_pages\", file_name)\n",
    "    course_code = file_name.split(\"_\")[0]\n",
    "    term = file_name.split(\"_\")[2].split(\".\")[0]\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        page = f.read()\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "\n",
    "    major_name = code2name.get(course_code, None)\n",
    "    course_texts = get_courses_info(soup, major_name)\n",
    "    \n",
    "    course_docs = []\n",
    "    for course_text in course_texts:\n",
    "        course_doc = {\n",
    "            \"major_code\": course_code,\n",
    "            \"term\": term,\n",
    "            \"content\": course_text\n",
    "        }\n",
    "        course_docs.append(course_doc)\n",
    "    all_course_docs.extend(course_docs)\n",
    "len(all_course_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"data/sabanci_course_docs.json\", \"w\") as f:\n",
    "#     json.dump(all_course_docs, f, indent=4)\n",
    "\n",
    "with open(\"data/sabanci_course_docs.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df[\"file_name\"] = df[\"major_code\"] + \"_\" + df[\"term\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in df[\"file_name\"].unique():\n",
    "    course_docs = df[df[\"file_name\"] == file_name][\"content\"].values\n",
    "    with open(f\"data/sabanci_course_docs/{file_name}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\\n\".join(course_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "concated_text = \"\\n\\n\".join([x[\"content\"] for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/sabanci_course_docs.txt\", \"w\") as f:\n",
    "    f.write(concated_text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
